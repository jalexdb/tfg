{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from datetime import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "w0 = 0.2\n",
    "w = 1.8\n",
    "alpha = 100\n",
    "h = 0.001\n",
    "wEE = 0\n",
    "wEI = 0\n",
    "wIE = 0\n",
    "wII = 0\n",
    "hE = h\n",
    "hI = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_W (N, w, w0, frac_inhib):\n",
    "    NI = int(N*frac_inhib)\n",
    "    NE = N - NI\n",
    "\n",
    "    wE = ((w+w0)/2)\n",
    "    wI = (wE-w0)\n",
    "\n",
    "    wE = wE/NE\n",
    "    wI = (-1)*wI/NI\n",
    "    W = np.zeros((N, N))\n",
    "\n",
    "    # Seleccionar aleatoriamente NI índices únicos para neuronas inhibitorias\n",
    "    is_inhibitory = np.random.choice(N, NI, replace=False)\n",
    "\n",
    "    # Las restantes serán neuronas excitatorias\n",
    "    is_excitatory = np.setdiff1d(np.arange(N), is_inhibitory)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i!=j:\n",
    "                if i in is_inhibitory:\n",
    "                    W[i][j] = wI\n",
    "                else:\n",
    "                    W[i][j] = wE\n",
    "\n",
    "    return W,is_excitatory, is_inhibitory, NE, NI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.where(x > 0, np.tanh(x), 0)\n",
    "\n",
    "\n",
    "# # Función de activación\n",
    "# def f(s):\n",
    "#     return np.tanh(s) * (s > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivadas deterministas\n",
    "def dE_dt(E, I):\n",
    "    sE = wEE * E - wEI * I + hE\n",
    "    return -alpha * E + (1 - E) * f(sE)\n",
    "\n",
    "def dI_dt(E, I):\n",
    "    sI = wIE * E - wII * I + hI\n",
    "    return -alpha * I + (1 - I) * f(sI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estado_inicial(Red, frac_active_NE=0.5, frac_active_NI=0.5, NE=0, NI=0, excit_indices= [], inhib_indices= []):\n",
    "\n",
    "    NE_activos = int(frac_active_NE * NE)\n",
    "    NI_activos = int(frac_active_NI * NI)\n",
    "\n",
    "    # Convertir a listas para usar con random.sample\n",
    "    inhib_indices = list(inhib_indices)\n",
    "    excit_indices = list(excit_indices)\n",
    "    \n",
    "    # Seleccionar índices aleatorios sin reemplazo usando numpy\n",
    "    inhib_seleccionados = np.random.choice(inhib_indices, size=NI_activos, replace=False)\n",
    "    excit_seleccionados = np.random.choice(excit_indices, size=NE_activos, replace=False)\n",
    "\n",
    "    indices_a_activar = np.concatenate([inhib_seleccionados, excit_seleccionados]).astype(np.int32)\n",
    "\n",
    "    # Activar los elementos seleccionados\n",
    "    Red[indices_a_activar] = 1\n",
    "\n",
    "    return Red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gillespie_algorithm(Red, W, T, log=0):\n",
    "    tiempo_inicio = time.time()\n",
    "\n",
    "    t = 0\n",
    "    times = [t]\n",
    "    rates = np.zeros(N)\n",
    "    States = []\n",
    "    Rates = []\n",
    "    Spikes = []\n",
    "    \n",
    "    States.append(Red.copy())\n",
    "    Rates.append(np.zeros(N))\n",
    "    Spikes.append(np.zeros(N))\n",
    "\n",
    "    step = 0\n",
    "    while t <= T:\n",
    "        spikes = np.zeros(N)\n",
    "        #Calculamos los rates       \n",
    "        r = 0\n",
    "        for i in range(N):\n",
    "            if Red[i] == 0: #=> La neurona está apagada f(s_i)\n",
    "                suma = h\n",
    "                for j in range(N):\n",
    "                    suma += Red[j]*W[j][i]\n",
    "                suma = f(suma)\n",
    "                rates[i] = suma\n",
    "                r += suma\n",
    "            else: #=> La neurona está encendida tiene un CD de alpha segundos\n",
    "                rates[i] = alpha\n",
    "                r += alpha\n",
    "\n",
    "        #Cuál debe ser el paso para que ocurra una \"reacción\"\n",
    "        u1, u2 = np.random.uniform(0, 1, 2)\n",
    "        \n",
    "        dt = (1/r)*np.log(1/u1)\n",
    "        #Qué neurona es la que sufre esa reacción?\n",
    "        suma = 0\n",
    "        i = 0\n",
    "        sigo = True\n",
    "        while i < N and sigo:\n",
    "            suma += rates[i] / r\n",
    "            if u2 <= suma:\n",
    "                neurona = i\n",
    "                sigo = False\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        #Cambio el estado de dicha neurona\n",
    "        if Red[neurona] == 0:\n",
    "            Red[neurona] = 1\n",
    "            spikes[neurona] = 1\n",
    "        elif Red[neurona] == 1:\n",
    "            Red[neurona] = 0\n",
    "\n",
    "        #Avanzo el tiempo\n",
    "        t += dt\n",
    "        if log > 0:\n",
    "            if (step % log == 0): \n",
    "                tiempo_actual = time.time()\n",
    "                tiempo_transcurrido = tiempo_actual - tiempo_inicio\n",
    "                print(\n",
    "                    f\"\\rSe han realizado {step+1} pasos | t={t:.3f}s ({t/T*100:.2f}%) | \"\n",
    "                    f\"Tiempo transcurrido: {tiempo_transcurrido:.2f}s | ETA: {tiempo_transcurrido/(t/T):.2f}s\",\n",
    "                    end=\"\",\n",
    "                    flush=True\n",
    "                )\n",
    "\n",
    "\n",
    "        step += 1\n",
    "        States.append(Red.copy())\n",
    "        Rates.append(rates.copy())\n",
    "        Spikes.append(spikes.copy())\n",
    "        times.append(t)\n",
    "\n",
    "    \n",
    "    print()\n",
    "    return np.array(States), np.array(Rates), np.array(Spikes), np.array(times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ISI(times, Spikes):\n",
    "    times = np.array(times)\n",
    "    Spikes = np.array(Spikes)  # Asegúrate de que es un array NumPy\n",
    "    \n",
    "    # Si Spikes es 2D (n_steps x n_neurons), busca cualquier spike por fila\n",
    "    if Spikes.ndim == 2:\n",
    "        mask = np.any(Spikes > 0, axis=1)\n",
    "    else:  # Si es 1D\n",
    "        mask = Spikes > 0\n",
    "\n",
    "    spike_times = times[mask]\n",
    "    isis = np.diff(spike_times)\n",
    "    \n",
    "    if len(isis) == 0:\n",
    "        return None  # o np.nan o lanzar un error\n",
    "    return np.mean(isis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avalanche_distribution(times, Spikes):\n",
    "    times = np.array(times)\n",
    "    Spikes = np.array(Spikes)\n",
    "    \n",
    "    # 1. Detectar tiempos de spike\n",
    "    if Spikes.ndim == 2:\n",
    "        mask = np.any(Spikes > 0, axis=1)\n",
    "    else:\n",
    "        mask = Spikes > 0\n",
    "\n",
    "    spike_times = times[mask]\n",
    "    \n",
    "    # Si no hay spikes suficientes, devolver lista vacía\n",
    "    if len(spike_times) < 2:\n",
    "        return []\n",
    "\n",
    "    # 2. Calcular ISI promedio\n",
    "    isi_avg = np.mean(np.diff(spike_times))\n",
    "    \n",
    "    # 3. Binarizar el tiempo en bins de tamaño ISI_avg\n",
    "    t_min, t_max = times[0], times[-1]\n",
    "    bins = np.arange(t_min, t_max + isi_avg, isi_avg)\n",
    "    binned_counts, _ = np.histogram(spike_times, bins=bins)\n",
    "\n",
    "    # 4. Detectar avalanchas: secuencias de bins con spikes (>0) separados por 0s\n",
    "    avalanches = []\n",
    "    size = 0\n",
    "    for count in binned_counts:\n",
    "        if count > 0:\n",
    "            size += count\n",
    "        elif size > 0:\n",
    "            avalanches.append(size)\n",
    "            size = 0\n",
    "    # Si termina con una avalancha activa\n",
    "    if size > 0:\n",
    "        avalanches.append(size)\n",
    "\n",
    "    return avalanches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_avalanche_distribution(times, Spikes):\n",
    "    avalanches = get_avalanche_distribution(times, Spikes)\n",
    "\n",
    "    if len(avalanches) == 0:\n",
    "        print(\"No se detectaron avalanchas.\")\n",
    "        return\n",
    "\n",
    "    # Histograma logarítmico\n",
    "    bins = np.logspace(np.log10(1), np.log10(max(avalanches)+1), num=20)\n",
    "    counts, edges = np.histogram(avalanches, bins=bins, density=True)\n",
    "\n",
    "    bin_centers = (edges[:-1] + edges[1:]) / 2\n",
    "\n",
    "    mask = counts > 0\n",
    "    x = bin_centers[mask]\n",
    "    y = counts[mask]\n",
    "    y = y / np.sum(y)\n",
    "\n",
    "    # Ajuste lineal en escala log-log\n",
    "    log_x = np.log10(x)\n",
    "    log_y = np.log10(y)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(log_x, log_y)\n",
    "\n",
    "    alpha = -slope  # ley de potencias: P(x) ~ x^(-alpha)\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(x, y, color='black', label='Datos')\n",
    "    plt.plot(x, 10**(intercept + slope * np.log10(x)), label=f'Ajuste (α ≈ {alpha:.2f})', linestyle='--')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Tamaño de avalancha')\n",
    "    plt.ylabel('Densidad de probabilidad')\n",
    "    plt.title('Distribución de tamaño de avalanchas')\n",
    "    plt.grid(True, which='both', ls='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Ajuste ley de potencias (estimación log-log): alpha ≈ {alpha:.2f}\")\n",
    "    print(f\"R² del ajuste: {r_value**2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros del sistema\n",
    "w_param = [0.8, 1.8, 13.8]\n",
    "\n",
    "for i in range(1):\n",
    "    N = 10000\n",
    "    frac_inhib = 0.5\n",
    "    w = w_param[i]\n",
    "    w0 = 0.2\n",
    "\n",
    "    W, excit_indices, inhib_indices, NE, NI = get_W(N, w, w0, frac_inhib=frac_inhib)\n",
    "    Red = get_estado_inicial(np.zeros(N), frac_active_NE=0.5, frac_active_NI=0.5, NE=NE, NI=NI, inhib_indices=inhib_indices, excit_indices=excit_indices)\n",
    "\n",
    "    #Parámetros de la simulación\n",
    "    T = 0.1\n",
    "\n",
    "    alpha = 0.1 #esto me imagino que lo tengo que pasar a segundos tau = 1ms + 9ms = 10ms\n",
    "    h = 0.001\n",
    "\n",
    "    States, Rates, Spikes, times= gillespie_algorithm(Red, W, T, log=100)\n",
    "\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # Para cada simulación\n",
    "    # np.savez_compressed(\n",
    "    #     f\"../Resultados/sim_{timestamp}.npz\",\n",
    "    #     W=W,\n",
    "    #     NE=NE,\n",
    "    #     NI=NI,\n",
    "    #     excit_indices=excit_indices, \n",
    "    #     inhib_indices=inhib_indices,\n",
    "    #     States=States,\n",
    "    #     Rates=Rates,\n",
    "    #     Spikes=Spikes,\n",
    "    #     Times=times,\n",
    "    #     N=N,\n",
    "    #     w=w,\n",
    "    #     w0=w0,\n",
    "    #     alpha=alpha,\n",
    "    #     h=h\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../Resultados/sim_20250707_191320.npz\")\n",
    "States = data[\"States\"]\n",
    "Rates = data[\"Rates\"]\n",
    "Spikes = data[\"Spikes\"]\n",
    "times = data[\"Times\"]\n",
    "N = int(data[\"N\"])\n",
    "w = float(data[\"w\"])\n",
    "w0 = float(data[\"w0\"])\n",
    "alpha = float(data[\"alpha\"])\n",
    "h = float(data[\"h\"])\n",
    "excit_indices = data[\"excit_indices\"]\n",
    "inhib_indices = data[\"inhib_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(N)\n",
    "inhib_indices = np.array(inhib_indices)\n",
    "excit_indices = np.setdiff1d(all_indices, inhib_indices)\n",
    "\n",
    "# Reordenamos usando bucles\n",
    "States_ordered = []\n",
    "Spikes_ordered = []\n",
    "Rates_ordered = []\n",
    "\n",
    "for t in range(len(States)):\n",
    "    s_ordered = np.concatenate([States[t][inhib_indices], States[t][excit_indices]])\n",
    "    sp_ordered = np.concatenate([Spikes[t][inhib_indices], Spikes[t][excit_indices]])\n",
    "    r_ordered = np.concatenate([Rates[t][inhib_indices], Rates[t][excit_indices]])\n",
    "    \n",
    "    States_ordered.append(s_ordered)\n",
    "    Spikes_ordered.append(sp_ordered)\n",
    "    Rates_ordered.append(r_ordered)\n",
    "\n",
    "# Convertimos a arrays para graficar\n",
    "States_ordered = np.array(States_ordered)\n",
    "Spikes_ordered = np.array(Spikes_ordered)\n",
    "Rates_ordered = np.array(Rates_ordered)\n",
    "\n",
    "\n",
    "mean_firing = np.mean(Rates, axis=1)\n",
    "std_firing = np.std(Rates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujamos las 3 matrices una debajo de otra\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 6), sharex=True)\n",
    "\n",
    "axes[0].imshow(np.transpose(States_ordered), cmap='gray_r', aspect='auto')\n",
    "axes[0].set_title(\"States\")\n",
    "\n",
    "axes[1].imshow(np.transpose(Spikes_ordered), cmap='gray_r', aspect='auto')\n",
    "axes[1].set_title(\"Spikes\")\n",
    "\n",
    "axes[2].imshow(np.transpose(Rates_ordered), cmap='gray_r', aspect='auto')\n",
    "axes[2].set_title(\"Rates\")\n",
    "axes[2].set_xlabel(\"Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_avalanche_distribution(times, Spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolución del sistema\n",
    "NI_evol = []\n",
    "NE_evol = []\n",
    "\n",
    "for step in States:\n",
    "    NI_active = sum(step[inhib_indices])\n",
    "    NE_active = sum(step[excit_indices])\n",
    "    NI_evol.append(NI_active/N*2)\n",
    "    NE_evol.append(NE_active/N*2)\n",
    "\n",
    "# Parámetros del modelo\n",
    "WE = (w+w0)/2\n",
    "WI = WE-w0\n",
    "wEE = WE\n",
    "wEI = WI\n",
    "wIE = WE\n",
    "wII = WI\n",
    "hE = h\n",
    "hI = h\n",
    "\n",
    "#Campo vectorial y las nulclinas\n",
    "E_field_vals = np.linspace(0, 1, 10)\n",
    "I_field_vals = np.linspace(0, 1, 10)\n",
    "E_field, I_field = np.meshgrid(E_field_vals, I_field_vals)\n",
    "\n",
    "dE = dE_dt(E_field, I_field)\n",
    "dI = dI_dt(E_field, I_field)\n",
    "\n",
    "# Normalizar vectores\n",
    "magnitude = np.sqrt(dE**2 + dI**2)\n",
    "dE_norm = dE*3\n",
    "dI_norm = dI*3\n",
    "\n",
    "E_contour_vals = np.linspace(0, 1, 50)\n",
    "I_contour_vals = np.linspace(0, 1, 50)\n",
    "E_contour, I_contour = np.meshgrid(E_contour_vals, I_contour_vals)\n",
    "\n",
    "dE_contour = dE_dt(E_contour, I_contour)\n",
    "dI_contour = dI_dt(E_contour, I_contour)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Campo vectorial\n",
    "plt.quiver(E_field, I_field, dE_norm, dI_norm, color='black', alpha=1, width=0.003, scale=40)\n",
    "\n",
    "# Nullclines\n",
    "cs1 = plt.contour(E_contour, I_contour, dE_contour, levels=[0], colors='red', linewidths=2, zorder=20)\n",
    "cs2 = plt.contour(E_contour, I_contour, dI_contour, levels=[0], colors='blue', linewidths=2, zorder=20)\n",
    "# plt.clabel(cs1, fmt={'0': '$dE/dt=0$'}, colors='red')\n",
    "# plt.clabel(cs2, fmt={'0': '$dI/dt=0$'}, colors='blue')\n",
    "\n",
    "# # Punto fijo\n",
    "# plt.scatter(\n",
    "#     E_fp, \n",
    "#     I_fp, \n",
    "#     facecolor=(1, 1, 1, 0), \n",
    "#     edgecolors=(0, 0, 0), \n",
    "#     label='Punto fijo',\n",
    "#     s=50,\n",
    "#     zorder=15)\n",
    "\n",
    "plt.plot(NE_evol, NI_evol, color=(0, 1, 0), label='Trayectoria')\n",
    "plt.scatter(\n",
    "    NE_evol[-1], \n",
    "    NI_evol[-1],\n",
    "    facecolor=(1, 1, 1, 0), \n",
    "    edgecolors=(1, 0, 0), \n",
    "    label='Punto final',\n",
    "    s=50,\n",
    "    zorder=10)\n",
    "\n",
    "plt.xlabel(\"E (actividad excitatoria)\")\n",
    "plt.ylabel(\"I (actividad inhibitoria)\")\n",
    "plt.title(fr\"w={w}, w0={w0}, h={h}, $\\alpha$={alpha}\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear malla fina para el fondo\n",
    "E_bg, I_bg = np.meshgrid(np.linspace(0, 1, 300), np.linspace(0, 1, 300))\n",
    "# Definir el gradiente como interpolación lineal entre dos esquinas\n",
    "gradient = -np.arctan(5*(E_bg - I_bg))\n",
    "# Crear el mapa de color personalizado\n",
    "cmap = LinearSegmentedColormap.from_list('strong_gradient', ['blue','blue', 'red', 'red'])\n",
    "# Definimos la función de activación (sigmoide tipo tanh truncada)\n",
    "def f(s):\n",
    "    return np.where(s >= 0, np.tanh(s), 0)\n",
    "\n",
    "# Parámetros del modelo\n",
    "alpha = 0.1\n",
    "w_EE = 1\n",
    "w_EI = 0.5\n",
    "w_IE = 1\n",
    "w_II = 0.5\n",
    "h_E = 0.001\n",
    "h_I = 0.001\n",
    "\n",
    "# Campo vectorial de las ecuaciones de Wilson-Cowan\n",
    "def dE_dt(E, I):\n",
    "    s_E = w_EE * E - w_EI * I + h_E\n",
    "    return -alpha * E + (1 - E) * f(s_E)\n",
    "\n",
    "def dI_dt(E, I):\n",
    "    s_I = w_IE * E - w_II * I + h_I\n",
    "    return -alpha * I + (1 - I) * f(s_I)\n",
    "\n",
    "# Definir sistema de ecuaciones para encontrar el punto fijo (intersección de nulclinas)\n",
    "def system(vars):\n",
    "    E, I = vars\n",
    "    eq1 = dE_dt(E, I)\n",
    "    eq2 = dI_dt(E, I)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "\n",
    "# Crear una malla de puntos en el espacio E-I\n",
    "E_vals = np.linspace(0, 1, 20)\n",
    "I_vals = np.linspace(0, 1, 20)\n",
    "E, I = np.meshgrid(E_vals, I_vals)\n",
    "dE = dE_dt(E, I)\n",
    "dI = dI_dt(E, I)\n",
    "\n",
    "\n",
    "# Usar fsolve para encontrar el punto fijo\n",
    "initial_guess = [0.5, 0.5]\n",
    "E_fp, I_fp = fsolve(system, initial_guess)\n",
    "\n",
    "# Calcular nulclinas: puntos donde dE/dt = 0 y dI/dt = 0\n",
    "E_nc = np.linspace(0, 1, 1000)\n",
    "I_nc = np.linspace(0, 1, 1000)\n",
    "EE, II = np.meshgrid(E_nc, I_nc)\n",
    "nullcline_E = dE_dt(EE, II)\n",
    "nullcline_I = dI_dt(EE, II)\n",
    "# Recalcular las nulclinas como listas separadas sin usar tuplas\n",
    "E_null_E = []\n",
    "I_null_E = []\n",
    "E_null_I = []\n",
    "I_null_I = []\n",
    "\n",
    "for e in E_nc:\n",
    "    i_e = fsolve(lambda i: dE_dt(e, i), 0.00001)[0]\n",
    "    if 0 <= i_e <= 1:\n",
    "        E_null_E.append(e)\n",
    "        I_null_E.append(i_e)\n",
    "\n",
    "    i_i = fsolve(lambda i: dI_dt(e, i), 0.00001)[0]\n",
    "    if 0 <= i_i <= 1:\n",
    "        E_null_I.append(e)\n",
    "        I_null_I.append(i_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, NI_evol, label=\"NI\", color=\"blue\")\n",
    "plt.plot(times, NE_evol, label=\"NE\", color=\"red\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"% activation\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, T)\n",
    "plt.title(\"Evolución de la actividad por tipo de neurona\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branching_data(times, Spikes):\n",
    "    times = np.array(times)\n",
    "    Spikes = np.array(Spikes)\n",
    "\n",
    "    if Spikes.ndim != 2:\n",
    "        raise ValueError(\"Spikes debe ser un array 2D (tiempo x canales)\")\n",
    "\n",
    "    # 1. Detectar actividad\n",
    "    active = np.any(Spikes > 0, axis=1)\n",
    "    spike_times = times[active]\n",
    "\n",
    "    if len(spike_times) < 2:\n",
    "        return [], []\n",
    "\n",
    "    isi_avg = np.mean(np.diff(spike_times))\n",
    "\n",
    "    # 2. Binarizar en bins temporales\n",
    "    t_min, t_max = times[0], times[-1]\n",
    "    bins = np.arange(t_min, t_max + isi_avg, isi_avg)\n",
    "    digitized = np.digitize(times, bins) - 1\n",
    "\n",
    "    # 3. Contar cuántos electrodos activos hay por bin temporal\n",
    "    binned_activity = np.zeros((len(bins)-1, Spikes.shape[1]), dtype=int)\n",
    "    for i in range(len(times)):\n",
    "        if 0 <= digitized[i] < len(binned_activity):\n",
    "            binned_activity[digitized[i]] |= (Spikes[i] > 0)\n",
    "\n",
    "    binned_counts = np.sum(binned_activity, axis=1)\n",
    "\n",
    "    # 4. Detectar avalanchas y recolectar na y nd\n",
    "    na_list = []\n",
    "    nd_list = []\n",
    "    i = 0\n",
    "    while i < len(binned_counts) - 1:\n",
    "        if binned_counts[i] > 0:\n",
    "            na = binned_counts[i]\n",
    "            nd = binned_counts[i + 1]\n",
    "            na_list.append(na)\n",
    "            nd_list.append(nd)\n",
    "            # avanzar hasta terminar avalancha\n",
    "            while i < len(binned_counts) and binned_counts[i] > 0:\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return na_list, nd_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_branching_parameter(ancestor_counts, descendant_counts, nmax):\n",
    "    assert len(ancestor_counts) == len(descendant_counts), \n",
    "    \n",
    "    p_d = {}\n",
    "    total_ancestors = 0\n",
    "    \n",
    "    for na, nd in zip(ancestor_counts, descendant_counts):\n",
    "        if na == 0:\n",
    "            continue\n",
    "        d = round(nd / na)\n",
    "        key = d\n",
    "        correction_factor = (nmax - 1) / (nmax - na) if (nmax - na) != 0 else 0\n",
    "        if key in p_d:\n",
    "            p_d[key]['na_sum'] += na * correction_factor\n",
    "            p_d[key]['count'] += 1\n",
    "        else:\n",
    "            p_d[key] = {'na_sum': na * correction_factor, 'count': 1}\n",
    "        total_ancestors += na\n",
    "\n",
    "    sigma = sum([d * (entry['na_sum'] / total_ancestors) for d, entry in p_d.items()])\n",
    "    return sigma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na, nd = get_branching_data(times, Spikes)\n",
    "sigma = compute_branching_parameter(na, nd, nmax=Spikes.shape[1])\n",
    "print(f\"Parámetro de branching estimado: σ ≈ {sigma:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
